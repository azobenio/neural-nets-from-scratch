{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MNIST('../', download=True, train=True)\n",
    "testset = MNIST('../', download=True, train=False)\n",
    "\n",
    "y_trainset = trainset.targets\n",
    "y_testset = testset.targets\n",
    "\n",
    "# this time, we resize the data to have directly one channel for convolutions\n",
    "trainset = trainset.data.reshape(60000, 1, 28, 28).to(torch.float32)\n",
    "testset = testset.data.reshape(10000, 1, 28, 28).to(torch.float32)\n",
    "\n",
    "# normalize\n",
    "m, s = trainset.mean(), trainset.std()\n",
    "trainset = (trainset - m) / s\n",
    "testset = (testset - m) / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import (not define) useful classes\n",
    "so far we've been defining Dataset, DataLoader and Optimizer. That was mainly an exercise to recreate them from scratch and get a deep understanding of what they do exactly. But we can now import them from Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    return (torch.argmax(output, dim=1) == target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still, we've got to create our own Dataset Class inheriting from Dataset\n",
    "class MNIST_Dataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid = trainset[0:50000, :], trainset[50000:, :]\n",
    "y_train, y_valid = y_trainset[0:50000], y_trainset[50000:]\n",
    "\n",
    "train = MNIST_Dataset(x_train, y_train)\n",
    "valid = MNIST_Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "bs = 64\n",
    "lr = 0.05\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train, bs, shuffle=True)\n",
    "valid_dl = DataLoader(valid, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def flatten(x):\n",
    "    return x.view(x.shape[0], -1)\n",
    "\n",
    "# Note: this architecture is absolutely not optimal\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=8,\n",
    "              kernel_size=3, stride=2, padding=1),  # bs*8*14*14\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(8, 16, 3, 2, 1),  # bs*16*7*7\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 32, 3, 2, 1),  # bs * 32 * 4 * 4\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, 3, 2, 1),  # bs * 64 * 2 * 2\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, 3, 2, 1),  # bs * 64 * 1 * 1\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(flatten),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "opt = SGD(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2128, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1608, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0003, grad_fn=<NllLossBackward>)\n",
      "CPU times: user 4min 9s, sys: 2min 57s, total: 7min 7s\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(EPOCHS):\n",
    "    for xb, yb in train_dl:\n",
    "        out = model(xb)\n",
    "        loss = loss_func(out, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the GPU to speed up computations requires... well, a gpu. Let's make sure we have one at our disposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got one. Now, we need to put both the model AND the data on the gpu. Putting a tensor on the gpu in pytorch is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (5): ReLU()\n",
       "  (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (7): ReLU()\n",
       "  (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (9): AdaptiveAvgPool2d(output_size=1)\n",
       "  (10): Lambda()\n",
       "  (11): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we've put the model on the gpu, but not the data. Let's see what happens if we try to model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(xb.shape)\n",
    "# model(xb)  # Uncomment this and you'll see the following error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an input type which is a classic tensor, and a weight type that is a torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  7.0674,  -6.0264,  -2.2024, -12.0934,   1.5402,   1.7699,  21.5525,\n",
       "         -10.4638,   2.1530,  -6.8926],\n",
       "        [ -5.4994,   1.5802,  -2.6634,  12.5096,  -0.1541,   2.5668,  -8.0999,\n",
       "          -2.3327,   0.0724,   1.2808],\n",
       "        [ -0.3200,  -0.1592,  -2.8402,  -3.1717,  -1.4508,   5.8560,  14.1711,\n",
       "          -9.7040,   2.7078,  -7.6999],\n",
       "        [ -7.4451,  -9.6124,  -6.1428,  10.0985,   6.5370,   0.6794, -14.1489,\n",
       "           3.3726,   2.3676,  19.9739],\n",
       "        [ -4.0804,  -1.2109,   3.3527,  -6.3227,  19.8378,  -6.0988,   0.3382,\n",
       "           2.5081,  -7.7397,  -0.7231],\n",
       "        [ -6.9855,  12.6681,   1.7988,   0.5260,   2.5971, -10.6724,  -4.8678,\n",
       "           5.8919,   0.5415,  -1.1746],\n",
       "        [ -5.8864,   1.2687,   0.3832,  10.3150,  -0.0888,   1.3408,  -2.2453,\n",
       "           0.1404,  -3.1439,  -5.0681],\n",
       "        [ -6.5852,   0.6337,  -4.2944,  -4.1017,  13.5828,  -3.3877,  -0.6945,\n",
       "           2.7353,   0.1108,   1.9531],\n",
       "        [ -2.6542,   6.7018,  13.7193,   6.2078, -10.4941,  -4.3374,  -8.3918,\n",
       "           1.0323,   4.4923,  -7.1434],\n",
       "        [ -4.7656,   4.9291,  20.7236,   4.5753,   4.0741,  -8.1187,  -0.5681,\n",
       "          -2.2992,  -5.7351, -17.0094],\n",
       "        [ -7.0119,  -2.8368,   1.4497,  17.3169,  -9.3091,   2.9746, -11.3101,\n",
       "           0.1313,   7.5487,  -0.1975],\n",
       "        [ 20.3896,  -5.8122,   7.5118,  -8.3168,  -8.5694,  -2.3267,   6.2779,\n",
       "          -8.1011,   2.4478,  -6.3061],\n",
       "        [ -8.9886,  14.1393,   1.5269,  -1.2364,   1.3404,  -8.4337,  -2.8724,\n",
       "           4.1521,   5.0937,  -4.7540],\n",
       "        [  1.0984,  -5.2140,  -2.2318,   0.6713,   5.1224,  -4.0422,  -5.2376,\n",
       "          -3.5325,   5.7172,  13.3526],\n",
       "        [ 18.8901,  -7.3488,   5.7347,  -5.5543, -11.0358,   0.2385,   1.0101,\n",
       "          -2.6761,   0.1841,  -2.6640],\n",
       "        [  0.0600,  -2.8337,  -0.9420,   1.0155,   2.6422,  -3.7091,  -4.9710,\n",
       "           1.4836,   0.7237,  10.5616]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb.cuda())  # This will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025713443756103516\n",
      "0.00010836124420166016\n",
      "0.015048742294311523\n",
      "0.0007213354110717773\n",
      "0.003766000270843506\n",
      "CPU times: user 9.97 s, sys: 2.3 s, total: 12.3 s\n",
      "Wall time: 7.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.cuda()  # We changed this\n",
    "for i in range(EPOCHS):\n",
    "    for xb, yb in train_dl:\n",
    "        out = model(xb.cuda())  # and this\n",
    "        loss = loss_func(out, yb.cuda())  # and this\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down to 7s, vs 22s earlier. That's 3 times faster! \n",
    "Of course, this improvement will depend on a number of factors: the complexity of the model, your gpu, etc. But a three-times improvement with such a simple architecture shows that using a GPU when you have access to one is simply a no-brainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's take a look at the losses:\n",
    "* 0.0025\n",
    "* 0.0001\n",
    "* 0.0150  (ouch, previous times 150!)\n",
    "* 0.0007\n",
    "* 0.0037\n",
    "\n",
    "The loss landscape is very bumpy!\n",
    "We could smoothen that out with batch-normalization. We'll do that next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
